{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from scipy.stats import kruskal, iqr\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr_file = \"../../data/qualitative_data/lqr_all_situations.csv\"\n",
    "pp_data_file = '../../data/experimental_data/experiment_actions.csv'\n",
    "model_score_file = \"../../data/input_cost_analysis/all_model_runs_on_situations_exo=0.01.csv\"\n",
    "conditions_file = \"../../data/experimental_data/experiment_conditions.csv\"\n",
    "n_pps = 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(pp_data_file)\n",
    "df_pps = df_data.loc[df_data.groupby('pp_id')['id'].idxmax()]\n",
    "df_lqr = pd.read_csv(lqr_file)\n",
    "df_model_scores = pd.read_csv(model_score_file)\n",
    "df_scores = pd.read_csv(model_score_file)\n",
    "df_conditions = pd.read_csv(conditions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditions['initial_endogenous'] = df_conditions['initial_endogenous'].apply(lambda x: str([int(y) for y in literal_eval(x)]))\n",
    "columns_to_keep = ['situation', 'lqr_score']\n",
    "df_lqr = df_lqr.merge(df_conditions, how='left', left_on='situation', right_on='initial_endogenous')[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_pp = df_data.groupby('pp_id').idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_easy = 0\n",
    "n_info = 0\n",
    "for c in df_by_pp['condition']:\n",
    "    cond = c % 30\n",
    "    if cond < 10:\n",
    "        n_easy += 1\n",
    "    else:\n",
    "        n_info += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.97751035077438"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median human performance, dropping outliers\n",
    "df_pps[df_pps['final_goal_distance'] < 1000]['final_goal_distance'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of participants who got within 100 points of the goal\n",
    "len(df_pps[df_pps['final_goal_distance'] < 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pps['root_cost'] = df_pps['total_cost'].apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mean and median costs and root costs for each model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = defaultdict(list)\n",
    "for index, row in df_pps.iterrows():\n",
    "\n",
    "    costs['human'].append(np.sqrt(row['total_cost']))\n",
    "    condition = int(row['condition'])\n",
    "    situation = []\n",
    "    costs['lqr'].append(df_lqr.loc[condition % 30]['lqr_score'])\n",
    "    for agent_type in (\"sparse_max_discrete\", \"sparse_max_continuous\", \"hill_climbing\", \"sparse_lqr\", \"null_model_2\"):\n",
    "        costs[agent_type].extend(df_model_scores[df_model_scores[\"model\"] == agent_type][\"performance\"])\n",
    "    \n",
    "avg_costs = {}\n",
    "med_costs = {}\n",
    "for agent_type in costs:\n",
    "    avg_costs[agent_type] = np.mean(costs[agent_type])\n",
    "    med_costs[agent_type] = np.median(costs[agent_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': 1033.664207131002,\n",
       " 'lqr': 5.451967123392466,\n",
       " 'sparse_max_discrete': 119.92250728389673,\n",
       " 'sparse_max_continuous': 1591.511809279578,\n",
       " 'hill_climbing': 86.19698409027524,\n",
       " 'sparse_lqr': 225.37704027698155,\n",
       " 'null_model_2': 340.28635176595054}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': 116.42950656942597,\n",
       " 'lqr': 4.683781147003174,\n",
       " 'sparse_max_discrete': 86.08562850952148,\n",
       " 'sparse_max_continuous': 285.10438537597656,\n",
       " 'hill_climbing': 67.06856155395508,\n",
       " 'sparse_lqr': 187.63528442382807,\n",
       " 'null_model_2': 332.38067626953125}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp_condition = df_pps.merge(df_conditions, left_on='condition', right_on='goal_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125.94903148468575\n",
      "113.60154048251282\n",
      "134.07002221277608\n",
      "112.88974575669928\n"
     ]
    }
   ],
   "source": [
    "df_pp_condition['root_cost'] = df_pp_condition['total_cost'].apply(np.sqrt)\n",
    "df_pp_condition = df_pp_condition[df_pp_condition['root_cost'] < 500]\n",
    "print(df_pp_condition[df_pp_condition['conditions'] == 'informative']['root_cost'].mean())\n",
    "print(df_pp_condition[df_pp_condition['conditions'] == 'informative']['root_cost'].median())\n",
    "print(df_pp_condition[df_pp_condition['conditions'] == 'easy']['root_cost'].mean())\n",
    "print(df_pp_condition[df_pp_condition['conditions'] == 'easy']['root_cost'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pps['condition_name'] = df_pps['condition'].apply(lambda x: \"informative\" if x % 30 >= 10 else \"easy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the median human score between easy and informative conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_costs = df_pps[df_pps['condition_name'] == 'easy']['root_cost']\n",
    "informative_costs = df_pps[df_pps['condition_name'] == 'informative']['root_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.29339106392572"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_costs.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.42950656942597"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informative_costs.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=0.0006036217304199454, pvalue=0.9803989740043368)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kruskal(easy_costs, informative_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.48676395243035"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iqr(df_pps['root_cost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
