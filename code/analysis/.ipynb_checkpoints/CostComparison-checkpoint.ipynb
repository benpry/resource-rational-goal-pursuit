{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from scipy.stats import kruskal, iqr\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqr_file = \"../../data/qualitative_data/lqr_all_situations.csv\"\n",
    "pp_data_file = '../../data/experimental_data/experiment_actions.csv'\n",
    "model_score_file = \"../../data/input_cost_analysis/all_model_runs_on_situations_exo=0.01.csv\"\n",
    "conditions_file = \"../../data/experimental_data/experiment_conditions.csv\"\n",
    "n_pps = 111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(pp_data_file)\n",
    "df_pps = df_data.loc[df_data.groupby('pp_id')['id'].idxmax()]\n",
    "df_lqr = pd.read_csv(lqr_file)\n",
    "df_model_scores = pd.read_csv(model_score_file)\n",
    "df_scores = pd.read_csv(model_score_file)\n",
    "df_conditions = pd.read_csv(conditions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conditions['initial_endogenous'] = df_conditions['initial_endogenous'].apply(lambda x: str([int(y) for y in literal_eval(x)]))\n",
    "columns_to_keep = ['situation', 'lqr_score']\n",
    "df_lqr = df_lqr.merge(df_conditions, how='left', left_on='situation', right_on='initial_endogenous')[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_pp = df_data.groupby('pp_id').idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_easy = 0\n",
    "n_info = 0\n",
    "for c in df_by_pp['condition']:\n",
    "    cond = c % 30\n",
    "    if cond < 10:\n",
    "        n_easy += 1\n",
    "    else:\n",
    "        n_info += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median human performance, dropping outliers\n",
    "df_pps[df_pps['final_goal_distance'] < 1000]['final_goal_distance'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of participants who got within 100 points of the goal\n",
    "len(df_pps[df_pps['final_goal_distance'] < 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pps['root_cost'] = df_pps['total_cost'].apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the mean and median costs and root costs for each model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = defaultdict(list)\n",
    "for index, row in df_pps.iterrows():\n",
    "\n",
    "    costs['human'].append(np.sqrt(row['total_cost']))\n",
    "    condition = int(row['condition'])\n",
    "    situation = []\n",
    "    costs['lqr'].append(df_lqr.loc[condition % 30]['lqr_score'])\n",
    "    for agent_type in (\"sparse_max_discrete\", \"sparse_max_continuous\", \"hill_climbing\", \"sparse_lqr\", \"null_model_2\"):\n",
    "        costs[agent_type].extend(df_model_scores[df_model_scores[\"model\"] == agent_type][\"performance\"])\n",
    "    \n",
    "avg_costs = {}\n",
    "med_costs = {}\n",
    "for agent_type in costs:\n",
    "    avg_costs[agent_type] = np.mean(costs[agent_type])\n",
    "    med_costs[agent_type] = np.median(costs[agent_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(root_costs['lqr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp_condition = df_pps.merge(df_conditions, left_on='condition', right_on='goal_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp_condition['root_cost'] = df_pp_condition['total_cost'].apply(np.sqrt)\n",
    "df_pp_condition = df_pp_condition[df_pp_condition['root_cost'] < 500]\n",
    "print(df_pp_condition[df_pp_condition['conditions'] == 'informative']['root_cost'].mean())\n",
    "print(df_pp_condition[df_pp_condition['conditions'] == 'informative']['root_cost'].median())\n",
    "print(df_pp_condition[df_pp_condition['conditions'] == 'easy']['root_cost'].mean())\n",
    "print(df_pp_condition[df_pp_condition['conditions'] == 'easy']['root_cost'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pps['condition_name'] = df_pps['condition'].apply(lambda x: \"informative\" if x % 30 >= 10 else \"easy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the median human score between easy and informative conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_costs = df_pps[df_pps['condition_name'] == 'easy']['root_cost']\n",
    "informative_costs = df_pps[df_pps['condition_name'] == 'informative']['root_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_costs.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "informative_costs.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal(easy_costs, informative_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr(df_pps['root_cost'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
